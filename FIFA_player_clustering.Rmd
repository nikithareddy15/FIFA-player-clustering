---
title: "2128240_MLA2_CIA2"
author: "Nikitha Reddy"
date: "2022-12-27"
output: html_document
---

## LOAD FIFA20 DATA

```{r}
# Load libraries
library(ggplot2)
library(tidyverse)
library(corrplot)
library(gridExtra)
library(GGally)
library(knitr)
library(cluster)
library(factoextra)
```


```{r}
getwd()
data=read.csv("sofifa20.csv", header = TRUE, row.names = "NAME")
```
```{r}
data1<-data
```


```{r}
kable(head(data1))
```
```{r}
kable(tail(data1))
```
```{r}
summary(data1)
```

```{r}
str(data1)
```


##Data Analysis

```{r}
# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA20 Attributes - Histograms") +
  theme_bw()
```

```{r}

# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA20 Attributes - Histograms") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA20 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA20 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Boxplot for each Attribute  
data1 %>%
  gather(Attributes, values, c(1,6:15)) %>%
  ggplot(aes(x=reorder(Attributes, values, FUN=median), y=values, fill=Attributes)) +
  geom_boxplot(show.legend=FALSE) +
  labs(title="Fifa Attributes - Boxplots") +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.title.x=element_blank()) +
  ylim(0, 35) +
  coord_flip()
```
```{r}
# Correlation matrix 
corrplot(cor(data1), type="upper", method="ellipse", tl.cex=0.65)
```
We find a strong correlation between few variables. So we can model the relationship between these two variables by fitting a linear equation

```{r}
# Relationship between Height and Balance
ggplot(data1, aes(x=HEIGHT, y=BALANCE)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="FIFA20 Attributes",
       subtitle="Relationship between Height and Balance") +
  theme_bw()
```

```{r}
# Relationship between Weight and Balance
ggplot(data1, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="FIFA20 Attributes",
       subtitle="Relationship between Weight and Balance") +
  theme_bw()
```
##Data Preparation

```{r}
# Normalization
fifaNorm <- as.data.frame(scale(data[1:50]))

# Original data
p1 <- ggplot(data1, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Original data") +
  theme_bw()

# Normalized data 
p2 <- ggplot(fifaNorm, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Normalized data") +
  theme_bw()

# Subplot
grid.arrange(p1, p2, ncol=2)
```
The points in the normalized data are the same as the original one. The only thing that changes is the scale of the axis.


## How many clusters?

```{r}
bss <- numeric()
wss <- numeric()

# Run the algorithm for different values of k 
set.seed(1234)

for(i in 1:10){

  # For each k, calculate betweenss and tot.withinss
  bss[i] <- kmeans(fifaNorm, centers=i)$betweenss
  wss[i] <- kmeans(fifaNorm, centers=i)$tot.withinss

}

# Between-cluster sum of squares vs Choice of k
p3 <- qplot(1:10, bss, geom=c("point", "line"), 
            xlab="Number of clusters", ylab="Between-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Total within-cluster sum of squares vs Choice of k
p4 <- qplot(1:10, wss, geom=c("point", "line"),
            xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Subplot
grid.arrange(p3, p4, ncol=2)
```

## KMeans

```{r}
library(funModeling)
profiling_num(data1)
```

```{r}
uns_df <- scale(data[1:50])

head(as_tibble(uns_df))
```

```{r}
distance <- get_dist(uns_df)
head(distance)
```

```{r}
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(uns_df, 
             center = 3,
             nstart = 25  )

str(k2)
```

```{r}
k2
```

```{r}
#Visulization of clusters
fviz_cluster(k2, data = uns_df, geom = c("point","text"))
```

```{r}
k2 <- kmeans(uns_df, centers = 2, nstart = 25)
k3 <- kmeans(uns_df, centers = 3, nstart = 25)
k4 <- kmeans(uns_df, centers = 4, nstart = 25)
k5 <- kmeans(uns_df, centers = 5, nstart = 25)

p1 <- fviz_cluster(k2, geom = "point", data = uns_df)+
  ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point", data = uns_df)+
  ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point", data = uns_df)+
  ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point", data = uns_df)+
  ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1,p2,p3,p4, nrow = 2)
```
## Optimum Cluster Number
```{r}
# Elbow Method
set.seed(123)
fviz_nbclust(uns_df, kmeans, method = "wss")
```


```{r}
set.seed(123)

final <- kmeans(uns_df, 3, nstart = 25)
final
```

```{r}
#Profile
fi20<-data1 %>% 
  mutate(Cluster = final$cluster) %>% 
  group_by(Cluster) %>% 
  summarise_all("mean")
fi20
getwd()
write.csv(fi20,"fi20.csv",row.names= FALSE)
```


##Hierarchical Clustering

```{r}

data3<-fifaNorm
xquant <- data3 # Numeric variables
    # Categorical variables
library(ClustOfVar)
#install.packages("hclustvar")
tree <- hclustvar(xquant)
```

```{r}
plot(tree, cex = 0.6)
```


```{r}
plot(tree, cex = 0.6)
rect.hclust(tree, k = 3, border = 2:4)
```
```{r}
stab <- stability(tree, B=50) # "B=50" refers to the number of bootstrap samples to use in the estimation.

d <- daisy(data3, metric="gower")

fit <- hclust(d=d, method="complete") 
plot(fit, cex = 0.6)
rect.hclust(fit, k = 3, border = 2:4)
```


## Load FIFA21 DATA


```{r}

getwd()
data=read.csv("sofifa21.csv", header = TRUE, row.names = "NAME")
```

```{r}
data1<-data
```


```{r}
kable(head(data1))
```

```{r}
kable(tail(data1))
```

```{r}
summary(data1)
```

```{r}
str(data1)
```

##Data Analysis

```{r}
# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA21 Attributes - Histograms") +
  theme_bw()
```

```{r}

# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA21 Attributes - Histograms") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA21 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA21 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Boxplot for each Attribute  
data1 %>%
  gather(Attributes, values, c(1,6:15)) %>%
  ggplot(aes(x=reorder(Attributes, values, FUN=median), y=values, fill=Attributes)) +
  geom_boxplot(show.legend=FALSE) +
  labs(title="Fifa Attributes - Boxplots") +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.title.x=element_blank()) +
  ylim(0, 35) +
  coord_flip()
```

##Data Preparation

```{r}
# Normalization
fifaNorm <- as.data.frame(scale(data[1:50]))

# Original data
p1 <- ggplot(data1, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Original data") +
  theme_bw()

# Normalized data 
p2 <- ggplot(fifaNorm, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Normalized data") +
  theme_bw()

# Subplot
grid.arrange(p1, p2, ncol=2)
```

The points in the normalized data are the same as the original one. The only thing that changes is the scale of the axis.





## How many clusters?

```{r}
bss <- numeric()
wss <- numeric()

# Run the algorithm for different values of k 
set.seed(1234)

for(i in 1:10){

  # For each k, calculate betweenss and tot.withinss
  bss[i] <- kmeans(fifaNorm, centers=i)$betweenss
  wss[i] <- kmeans(fifaNorm, centers=i)$tot.withinss

}

# Between-cluster sum of squares vs Choice of k
p3 <- qplot(1:10, bss, geom=c("point", "line"), 
            xlab="Number of clusters", ylab="Between-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Total within-cluster sum of squares vs Choice of k
p4 <- qplot(1:10, wss, geom=c("point", "line"),
            xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Subplot
grid.arrange(p3, p4, ncol=2)
```

## KMeans

```{r}
library(funModeling)
profiling_num(data1)
```

```{r}
uns_df <- scale(data[1:50])

head(as_tibble(uns_df))
```

```{r}
distance <- get_dist(uns_df)
head(distance)
```


```{r}
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```


```{r}
k2 <- kmeans(uns_df, 
             center = 3,
             nstart = 25  )

str(k2)
```

```{r}
k2
```

```{r}
# visulization of clusters
fviz_cluster(k2, data = uns_df, geom = c("point","text"))
```

```{r}
k2 <- kmeans(uns_df, centers = 2, nstart = 25)
k3 <- kmeans(uns_df, centers = 3, nstart = 25)
k4 <- kmeans(uns_df, centers = 4, nstart = 25)
k5 <- kmeans(uns_df, centers = 5, nstart = 25)

p1 <- fviz_cluster(k2, geom = "point", data = uns_df)+
  ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point", data = uns_df)+
  ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point", data = uns_df)+
  ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point", data = uns_df)+
  ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1,p2,p3,p4, nrow = 2)
```

## Optimum Cluster Number
```{r}
# Elbow Method
set.seed(123)
fviz_nbclust(uns_df, kmeans, method = "wss")
```

```{r}
set.seed(123)

final <- kmeans(uns_df, 3, nstart = 25)
final
```

```{r}
#Business profile
fi21<-data1 %>% 
  mutate(Cluster = final$cluster) %>% 
  group_by(Cluster) %>% 
  summarise_all("mean")
fi21
getwd()
write.csv(fi21,"fi21.csv",row.names= FALSE)
```

##Hierarchical Clustering

```{r}

data3<-fifaNorm
xquant <- data3 # Numeric variables
    # Categorical variables
library(ClustOfVar)
#install.packages("hclustvar")
tree <- hclustvar(xquant)
```

```{r}
plot(tree, cex = 0.6)
```


```{r}
plot(tree, cex = 0.6)
rect.hclust(tree, k = 3, border = 2:4)
```
```{r}
stab <- stability(tree, B=50) # "B=50" refers to the number of bootstrap samples to use in the estimation.

d <- daisy(data3, metric="gower")

fit <- hclust(d=d, method="complete")    # Also try: method="ward.D"   

plot(fit, cex = 0.6)
rect.hclust(fit, k = 3, border = 2:4)
```





## LOAD FIFA22 DATA

```{r}
# Load libraries

library(tidyverse)
library(corrplot)
library(gridExtra)
library(GGally)
library(knitr)
```

```{r}
getwd()
data=read.csv("sofifa22.csv", header = TRUE, row.names = "NAME")
```


```{r}
data1<-data
```

```{r}
kable(head(data1))
```

```{r}
kable(tail(data1))
```

```{r}
summary(data1)
```

```{r}
str(data1)
```

##Data Analysis

```{r}
# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA22 Attributes - Histograms") +
  theme_bw()
```

```{r}

# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA22 Attributes - Histograms") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA22 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 26:50) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA22 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Boxplot for each Attribute  
data1 %>%
  gather(Attributes, values, c(1,6:15)) %>%
  ggplot(aes(x=reorder(Attributes, values, FUN=median), y=values, fill=Attributes)) +
  geom_boxplot(show.legend=FALSE) +
  labs(title="Fifa Attributes - Boxplots") +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.title.x=element_blank()) +
  ylim(0, 35) +
  coord_flip()
```

##Data Preparation

```{r}
# Normalization
fifaNorm <- as.data.frame(scale(data[1:50]))

# Original data
p1 <- ggplot(data1, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Original data") +
  theme_bw()

# Normalized data 
p2 <- ggplot(fifaNorm, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Normalized data") +
  theme_bw()

# Subplot
grid.arrange(p1, p2, ncol=2)
```

The points in the normalized data are the same as the original one. The only thing that changes is the scale of the axis.

## How many clusters?

```{r}
bss <- numeric()
wss <- numeric()

# Run the algorithm for different values of k 
set.seed(1234)

for(i in 1:10){

  # For each k, calculate betweenss and tot.withinss
  bss[i] <- kmeans(fifaNorm, centers=i)$betweenss
  wss[i] <- kmeans(fifaNorm, centers=i)$tot.withinss

}

# Between-cluster sum of squares vs Choice of k
p3 <- qplot(1:10, bss, geom=c("point", "line"), 
            xlab="Number of clusters", ylab="Between-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Total within-cluster sum of squares vs Choice of k
p4 <- qplot(1:10, wss, geom=c("point", "line"),
            xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Subplot
grid.arrange(p3, p4, ncol=2)
```


## KMeans

```{r}
library(funModeling)
profiling_num(data1)
```

```{r}
uns_df <- scale(data[1:50])

head(as_tibble(uns_df))
```

```{r}
distance <- get_dist(uns_df)
head(distance)
```


```{r}
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```


```{r}
k2 <- kmeans(uns_df, 
             center = 3,
             nstart = 25  )

str(k2)
```

```{r}
k2
```

```{r}
fviz_cluster(k2, data = uns_df, geom = c("point","text"))
```

```{r}
k2 <- kmeans(uns_df, centers = 2, nstart = 25)
k3 <- kmeans(uns_df, centers = 3, nstart = 25)
k4 <- kmeans(uns_df, centers = 4, nstart = 25)
k5 <- kmeans(uns_df, centers = 5, nstart = 25)

p1 <- fviz_cluster(k2, geom = "point", data = uns_df)+
  ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point", data = uns_df)+
  ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point", data = uns_df)+
  ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point", data = uns_df)+
  ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1,p2,p3,p4, nrow = 2)
```

## Optimum Cluster Number
```{r}
# Elbow Method
set.seed(123)
fviz_nbclust(uns_df, kmeans, method = "wss")
```

```{r}
set.seed(123)

final <- kmeans(uns_df, 3, nstart = 25)
final
```

```{r}
fi22<-data1 %>% 
  mutate(Cluster = final$cluster) %>% 
  group_by(Cluster) %>% 
  summarise_all("mean")
fi22
getwd()
write.csv(fi22,"fi22.csv",row.names= FALSE)
```

##Hierarchical Clustering

```{r}

data3<-fifaNorm
xquant <- data3 # Numeric variables
    # Categorical variables
library(ClustOfVar)
#install.packages("hclustvar")
tree <- hclustvar(xquant)
```

```{r}
plot(tree, cex = 0.6)
```


```{r}
plot(tree, cex = 0.6)
rect.hclust(tree, k = 3, border = 2:4)
```
```{r}
stab <- stability(tree, B=50) # "B=50" refers to the number of bootstrap samples to use in the estimation.

d <- daisy(data3, metric="gower")

fit <- hclust(d=d, method="complete")    # Also try: method="ward.D"   
plot(fit, cex = 0.6)
rect.hclust(fit, k = 3, border = 2:4)
```


## LOAD FIFA23 DATA

```{r}
# Load libraries

library(tidyverse)
library(corrplot)
library(gridExtra)
library(GGally)
library(knitr)
```

```{r}
getwd()
data=read.csv("sofifa23.csv", header = TRUE, row.names = "NAME")
```

```{r}
data1<-data
str(data1)
```

```{r}
kable(head(data1))
```

```{r}
kable(tail(data1))
```

```{r}
summary(data1)
```

```{r}
str(data1)
```

##Data Analysis

```{r}
# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA23 Attributes - Histograms") +
  theme_bw()
```

```{r}

# Histogram for each Attribute
data1 %>%
  gather(Attributes, value, 26:49) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_histogram(colour="black", show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency",
       title="FIFA23 Attributes - Histograms") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 1:25) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA23 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Density plot for each Attribute
data1 %>%
  gather(Attributes, value, 26:49) %>%
  ggplot(aes(x=value, fill=Attributes)) +
  geom_density(colour="black", alpha=0.5, show.legend=FALSE) +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Density",
       title="FIFA23 Attributes - Density plots") +
  theme_bw()
```

```{r}
# Boxplot for each Attribute  
data1 %>%
  gather(Attributes, values, c(1,6:15)) %>%
  ggplot(aes(x=reorder(Attributes, values, FUN=median), y=values, fill=Attributes)) +
  geom_boxplot(show.legend=FALSE) +
  labs(title="Fifa Attributes - Boxplots") +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.title.x=element_blank()) +
  ylim(0, 35) +
  coord_flip()
```

##Data Preparation

```{r}
# Normalization
fifaNorm <- as.data.frame(scale(data[1:50]))

# Original data
p1 <- ggplot(data1, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Original data") +
  theme_bw()

# Normalized data 
p2 <- ggplot(fifaNorm, aes(x=WEIGHT, y=BALANCE)) +
  geom_point() +
  labs(title="Normalized data") +
  theme_bw()

# Subplot
grid.arrange(p1, p2, ncol=2)
```

The points in the normalized data are the same as the original one. The only thing that changes is the scale of the axis.

## How many clusters?

```{r}
bss <- numeric()
wss <- numeric()

# Run the algorithm for different values of k 
set.seed(1234)

for(i in 1:10){

  # For each k, calculate betweenss and tot.withinss
  bss[i] <- kmeans(fifaNorm, centers=i)$betweenss
  wss[i] <- kmeans(fifaNorm, centers=i)$tot.withinss

}

# Between-cluster sum of squares vs Choice of k
p3 <- qplot(1:10, bss, geom=c("point", "line"), 
            xlab="Number of clusters", ylab="Between-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Total within-cluster sum of squares vs Choice of k
p4 <- qplot(1:10, wss, geom=c("point", "line"),
            xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1)) +
  theme_bw()

# Subplot
grid.arrange(p3, p4, ncol=2)
```


## KMeans

```{r}
library(funModeling)
profiling_num(data1)
```

```{r}
uns_df <- scale(data[1:50])

head(as_tibble(uns_df))
```

```{r}
library(cluster)
library(factoextra)
distance <- get_dist(uns_df)
head(distance)
```


```{r}
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```


```{r}
k2 <- kmeans(uns_df, 
             center = 4,
             nstart = 25  )

str(k2)
```

```{r}
k2
```

```{r}
fviz_cluster(k2, data = uns_df, geom = c("point","text"))

```

```{r}
k2 <- kmeans(uns_df, centers = 2, nstart = 25)
k3 <- kmeans(uns_df, centers = 3, nstart = 25)
k4 <- kmeans(uns_df, centers = 4, nstart = 25)
k5 <- kmeans(uns_df, centers = 5, nstart = 25)

p1 <- fviz_cluster(k2, geom = "point", data = uns_df)+
  ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point", data = uns_df)+
  ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point", data = uns_df)+
  ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point", data = uns_df)+
  ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1,p2,p3,p4, nrow = 2)
```

## Optimum Cluster Number
```{r}
# Elbow Method
set.seed(123)
fviz_nbclust(uns_df, kmeans, method = "wss")
```

```{r}
set.seed(123)

final <- kmeans(uns_df, 4, nstart = 25)
final
```

```{r}
fi23<-data1 %>% 
  mutate(Cluster = final$cluster) %>% 
  group_by(Cluster) %>% 
  summarise_all("mean")
fi23
getwd()
write.csv(fi23,"fi23.csv",row.names= FALSE)
```

##Hierarchical Clustering

```{r}
library(cluster)
data3<-fifaNorm
xquant <- data3 # Numeric variables
    # Categorical variables
library(ClustOfVar)
#install.packages("hclustvar")
tree <- hclustvar(xquant)

```

```{r}
plot(tree, cex = 0.6)

```
```{r}
plot(tree, cex = 0.6)
rect.hclust(tree, k = 4, border = 2:4)
```



```{r}
stab <- stability(tree, B=50) # "B=50" refers to the number of bootstrap samples to use in the estimation.

d <- daisy(data3, metric="gower")

fit <- hclust(d=d, method="complete")    # Also try: method="ward.D"   
plot(fit, cex = 0.6)
rect.hclust(fit, k = 4, border = 2:4)
```

